{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65a2b57-0b94-4a18-b68b-0cee4c4a443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ShapeR'...\n",
      "remote: Enumerating objects: 306, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 306 (delta 12), reused 6 (delta 5), pack-reused 280 (from 1)\u001b[K\n",
      "Receiving objects: 100% (306/306), 41.25 MiB | 34.26 MiB/s, done.\n",
      "Resolving deltas: 100% (73/73), done.\n",
      "Updating files: 100% (212/212), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone git@github.com:facebookresearch/ShapeR.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3acf88-0f14-473f-a2ad-b12d999be16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.12/site-packages (0.45.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (75.8.0)\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.13.0\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.67.1)\n",
      "Collecting hydra-core\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (4.11.0)\n",
      "Requirement already satisfied: imageio in /opt/conda/lib/python3.12/site-packages (2.36.1)\n",
      "Collecting easydict\n",
      "  Downloading easydict-1.13-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting munch\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting plyfile\n",
      "  Using cached plyfile-1.1.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting omegaconf<2.4,>=2.2 (from hydra-core)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip install wheel setuptools ninja\n",
    "!pip install numpy tqdm hydra-core matplotlib opencv-python imageio easydict munch plyfile\n",
    "!pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu128\n",
    "!pip install transformers trimesh scikit-image diffusers gradio peft einops\n",
    "!pip install flash-attn --no-build-isolation --no-cache-dir\n",
    "!pip install \"imageio[ffmpeg]\" \"imageio[pyav]\"\n",
    "!pip install pymeshlab sophuspy fast_simplification scikit-learn timm plotly torchdiffeq sentencepiece protobuf pyrender jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3b3047-3342-460b-85a3-a2463d09935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.7.1+cu128.html\n",
      "Collecting torch-cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/torch_cluster-1.6.3%2Bpt27cu128-cp312-cp312-linux_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from torch-cluster) (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.12/site-packages (from scipy->torch-cluster) (1.26.4)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.3+pt27cu128\n",
      "Using pip 25.0 from /opt/conda/lib/python3.12/site-packages/pip (python 3.12)\n",
      "Collecting git+https://github.com/nihalsid/torchsparse@legacy\n",
      "  Cloning https://github.com/nihalsid/torchsparse (to revision legacy) to /tmp/pip-req-build-gotuyqh4\n",
      "  Running command git version\n",
      "  git version 2.43.0\n",
      "  Running command git clone --filter=blob:none https://github.com/nihalsid/torchsparse /tmp/pip-req-build-gotuyqh4\n",
      "  Cloning into '/tmp/pip-req-build-gotuyqh4'...\n",
      "  Running command git show-ref legacy\n",
      "  20ccc92a3adceef1d88f63227b8e1d01b9c7ebcc refs/remotes/origin/legacy\n",
      "  Running command git symbolic-ref -q HEAD\n",
      "  refs/heads/master\n",
      "  Running command git checkout -b legacy --track origin/legacy\n",
      "  Switched to a new branch 'legacy'\n",
      "  branch 'legacy' set up to track 'origin/legacy'.\n",
      "  Resolved https://github.com/nihalsid/torchsparse to commit 20ccc92a3adceef1d88f63227b8e1d01b9c7ebcc\n",
      "  Running command git rev-parse HEAD\n",
      "  20ccc92a3adceef1d88f63227b8e1d01b9c7ebcc\n",
      "  Running command python setup.py egg_info\n",
      "  running egg_info\n",
      "  creating /tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info\n",
      "  writing /tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/PKG-INFO\n",
      "  writing dependency_links to /tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/dependency_links.txt\n",
      "  writing top-level names to /tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/top_level.txt\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/SOURCES.txt'\n",
      "  /opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  reading manifest file '/tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file '/tmp/pip-pip-egg-info-xzfxj1ap/torchsparse.egg-info/SOURCES.txt'\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: torchsparse\n",
      "  Running command git rev-parse HEAD\n",
      "  20ccc92a3adceef1d88f63227b8e1d01b9c7ebcc\n",
      "  Running command python setup.py bdist_wheel\n",
      "  running bdist_wheel\n",
      "  /opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "    warnings.warn(msg.format('we could not find ninja.'))\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  copying torchsparse/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  copying torchsparse/operators.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  copying torchsparse/tensor.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  copying torchsparse/version.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse/nn\n",
      "  copying torchsparse/nn/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  copying torchsparse/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  copying torchsparse/utils/collate.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  copying torchsparse/utils/quantize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  copying torchsparse/utils/utils.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/activation.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/conv.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/count.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/crop.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/devoxelize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/downsample.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/hash.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/pooling.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/query.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  copying torchsparse/nn/functional/voxelize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/activation.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/bev.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/conv.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/crop.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/norm.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  copying torchsparse/nn/modules/pooling.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  copying torchsparse/nn/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  copying torchsparse/nn/utils/apply.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  copying torchsparse/nn/utils/kernel.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  running build_ext\n",
      "  building 'torchsparse.backend' extension\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/convolution\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/devoxelize\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/hash\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/others\n",
      "  creating build/temp.linux-x86_64-cpython-312/torchsparse/backend/voxelize\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c torchsparse/backend/convolution/convolution_cpu.cpp -o build/temp.linux-x86_64-cpython-312/torchsparse/backend/convolution/convolution_cpu.o -g -O3 -fopenmp -lgomp -I -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c torchsparse/backend/devoxelize/devoxelize_cpu.cpp -o build/temp.linux-x86_64-cpython-312/torchsparse/backend/devoxelize/devoxelize_cpu.o -g -O3 -fopenmp -lgomp -I -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c torchsparse/backend/hash/hash_cpu.cpp -o build/temp.linux-x86_64-cpython-312/torchsparse/backend/hash/hash_cpu.o -g -O3 -fopenmp -lgomp -I -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  g++ -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c torchsparse/backend/hashmap/hashmap_cpu.cpp -o build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o -g -O3 -fopenmp -lgomp -I -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  In file included from torchsparse/backend/hashmap/hashmap_cpu.cpp:1:\n",
      "  torchsparse/backend/hashmap/hashmap_cpu.hpp:8:10: fatal error: google/dense_hash_map: No such file or directory\n",
      "      8 | #include <google/dense_hash_map>\n",
      "        |          ^~~~~~~~~~~~~~~~~~~~~~~\n",
      "  compilation terminated.\n",
      "  error: command '/usr/bin/g++' failed with exit code 1\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  \u001b[1;35mfull command\u001b[0m: \u001b[34m/opt/conda/bin/python3.12 -u -c '\u001b[0m\n",
      "\u001b[34m  exec(compile('\"'\"''\"'\"''\"'\"'\u001b[0m\n",
      "\u001b[34m  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "\u001b[34m  #\u001b[0m\n",
      "\u001b[34m  # - It imports setuptools before invoking setup.py, to enable projects that directly\u001b[0m\n",
      "\u001b[34m  #   import from `distutils.core` to work with newer packaging standards.\u001b[0m\n",
      "\u001b[34m  # - It provides a clear error message when setuptools is not installed.\u001b[0m\n",
      "\u001b[34m  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so\u001b[0m\n",
      "\u001b[34m  #   setuptools doesn'\"'\"'t think the script is `-c`. This avoids the following warning:\u001b[0m\n",
      "\u001b[34m  #     manifest_maker: standard file '\"'\"'-c'\"'\"' not found\".\u001b[0m\n",
      "\u001b[34m  # - It generates a shim setup.py, for handling setup.cfg-only projects.\u001b[0m\n",
      "\u001b[34m  import os, sys, tokenize\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  try:\u001b[0m\n",
      "\u001b[34m      import setuptools\u001b[0m\n",
      "\u001b[34m  except ImportError as error:\u001b[0m\n",
      "\u001b[34m      print(\u001b[0m\n",
      "\u001b[34m          \"ERROR: Can not execute `setup.py` since setuptools is not available in \"\u001b[0m\n",
      "\u001b[34m          \"the build environment.\",\u001b[0m\n",
      "\u001b[34m          file=sys.stderr,\u001b[0m\n",
      "\u001b[34m      )\u001b[0m\n",
      "\u001b[34m      sys.exit(1)\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  __file__ = %r\u001b[0m\n",
      "\u001b[34m  sys.argv[0] = __file__\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  if os.path.exists(__file__):\u001b[0m\n",
      "\u001b[34m      filename = __file__\u001b[0m\n",
      "\u001b[34m      with tokenize.open(__file__) as f:\u001b[0m\n",
      "\u001b[34m          setup_py_code = f.read()\u001b[0m\n",
      "\u001b[34m  else:\u001b[0m\n",
      "\u001b[34m      filename = \"<auto-generated setuptools caller>\"\u001b[0m\n",
      "\u001b[34m      setup_py_code = \"from setuptools import setup; setup()\"\u001b[0m\n",
      "\u001b[34m  \u001b[0m\n",
      "\u001b[34m  exec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "\u001b[34m  '\"'\"''\"'\"''\"'\"' % ('\"'\"'/tmp/pip-req-build-gotuyqh4/setup.py'\"'\"',), \"<pip-setuptools-caller>\", \"exec\"))' bdist_wheel -d /tmp/pip-wheel-0d2w9utx\u001b[0m\n",
      "  \u001b[1;35mcwd\u001b[0m: /tmp/pip-req-build-gotuyqh4/\n",
      "  Building wheel for torchsparse (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for torchsparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torchsparse\n",
      "  Running command python setup.py clean\n",
      "  running clean\n",
      "  removing 'build/temp.linux-x86_64-cpython-312' (and everything under it)\n",
      "  removing 'build/lib.linux-x86_64-cpython-312' (and everything under it)\n",
      "  'build/bdist.linux-x86_64' does not exist -- can't clean it\n",
      "  'build/scripts-3.12' does not exist -- can't clean it\n",
      "  removing 'build'\n",
      "Failed to build torchsparse\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (torchsparse)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.7.1+cu128.html\n",
    "!pip install --verbose git+https://github.com/nihalsid/torchsparse@legacy --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2938ba43-ac0d-48c0-afe3-7a12feabc4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from torch-sparse) (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.12/site-packages (from scipy->torch-sparse) (1.26.4)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.18\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "213a122b-b284-4860-b88f-2724e76fb329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b07b9c3-28ac-4165-8a91-36180fbec301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch-sparse works ✅\n",
      "SparseTensor(row=tensor([1, 4], device='cuda:0'),\n",
      "             col=tensor([2, 5], device='cuda:0'),\n",
      "             val=tensor([-0.3385, -1.3784], device='cuda:0'),\n",
      "             size=(5, 6), nnz=2, density=6.67%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "row = torch.tensor([1, 4], device=device)\n",
    "col = torch.tensor([2, 5], device=device)\n",
    "value = torch.randn(2, device=device)\n",
    "\n",
    "x = SparseTensor(row=row, col=col, value=value)\n",
    "\n",
    "print(\"torch-sparse works ✅\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88a3e99e-ebe5-40f5-958e-04824d1941a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/14_secs/frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75400ab3-6e06-4c6d-a45f-cecf1248ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 13M Feb  6 04:10 data/14_secs.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/14_secs.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6223e86f-15bb-471d-9e9b-9001e78ea8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to repair the video file...\n",
      "\n",
      "Extracting frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 13.3.0 (conda-forge gcc 13.3.0-2)\n",
      "  configuration: --prefix=/opt/conda --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --disable-gnutls --enable-libvpx --enable-libass --enable-pthreads --enable-alsa --enable-libpulse --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libmp3lame --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x643e858d63c0] moov atom not found\n",
      "[in#0 @ 0x643e858d6100] Error opening input: Invalid data found when processing input\n",
      "Error opening input file data/14_secs.mp4.\n",
      "Error opening input files: Invalid data found when processing input\n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 13.3.0 (conda-forge gcc 13.3.0-2)\n",
      "  configuration: --prefix=/opt/conda --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --disable-gnutls --enable-libvpx --enable-libass --enable-pthreads --enable-alsa --enable-libpulse --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libmp3lame --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[in#0 @ 0x5d1b9a649080] Error opening input: No such file or directory\n",
      "Error opening input file data/14_secs_fixed.mp4.\n",
      "Error opening input files: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-i', 'data/14_secs_fixed.mp4', '-vf', 'fps=30', 'data/frames/frame_%04d.png']' returned non-zero exit status 254.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mExtracting frames...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/frames\u001b[39m\u001b[38;5;124m'\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mffmpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-i\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/14_secs_fixed.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-vf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfps=30\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/frames/frame_\u001b[39;49m\u001b[38;5;132;43;01m%04d\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Load frames\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-i', 'data/14_secs_fixed.mp4', '-vf', 'fps=30', 'data/frames/frame_%04d.png']' returned non-zero exit status 254."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# First, try to repair/re-encode the video\n",
    "print(\"Attempting to repair the video file...\")\n",
    "subprocess.run([\n",
    "    'ffmpeg', '-i', 'data/14_secs.mp4',\n",
    "    '-c', 'copy',\n",
    "    '-movflags', 'faststart',\n",
    "    'data/14_secs_fixed.mp4'\n",
    "])\n",
    "\n",
    "# Now extract frames from the fixed video\n",
    "print(\"\\nExtracting frames...\")\n",
    "os.makedirs('data/frames', exist_ok=True)\n",
    "subprocess.run([\n",
    "    'ffmpeg', '-i', 'data/14_secs_fixed.mp4',\n",
    "    '-vf', 'fps=30',\n",
    "    'data/frames/frame_%04d.png'\n",
    "], check=True)\n",
    "\n",
    "# Load frames\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "frame_files = sorted(Path('data/frames').glob(\"*.png\"))\n",
    "print(f\"Loading {len(frame_files)} frames...\")\n",
    "\n",
    "frames = [np.array(Image.open(f)) for f in frame_files]\n",
    "frames_array = np.array(frames)\n",
    "\n",
    "# Save as pickle\n",
    "with open('data/frames.pkl', 'wb') as f:\n",
    "    pickle.dump(frames_array, f)\n",
    "\n",
    "print(f\"\\nDone!\")\n",
    "print(f\"Frames shape: {frames_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adce9c42-f22b-4df8-b33b-9b7177ccc2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from data/output.mp4...\n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 13.3.0 (conda-forge gcc 13.3.0-2)\n",
      "  configuration: --prefix=/opt/conda --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --disable-gnutls --enable-libvpx --enable-libass --enable-pthreads --enable-alsa --enable-libpulse --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libmp3lame --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1743376049581/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "  Duration: 00:00:31.50, start: 0.000000, bitrate: 110648 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 2880x2880, 110646 kb/s, 10 fps, 10 tbr, 10240 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'data/frames/frame_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/unknown/unknown, progressive), 2880x2880, q=2-31, 200 kb/s, 30 fps, 30 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.101 png\n",
      "\u001b[1;35m[out#0/image2 @ 0x6163e8d88340] \u001b[0mvideo:18300380KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=  945 fps=1.0 q=-0.0 Lsize=N/A time=00:00:31.50 bitrate=N/A speed=0.0341x    \n",
      "Loading 945 frames...\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/video_to_frames.py\", line 32, in <module>\n"
     ]
    }
   ],
   "source": [
    "!python video_to_frames.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a16093-901e-41ea-ba67-7afcc416a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Extracted 105 frames\n",
      "Shape: (105, 720, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "cap = cv2.VideoCapture('data/output.mp4')\n",
    "frames = []\n",
    "\n",
    "# Extract every Nth frame to reduce count\n",
    "frame_skip = 3  # Only take every 3rd frame\n",
    "frame_num = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    if frame_num % frame_skip == 0:\n",
    "        # Resize to smaller resolution\n",
    "        frame_resized = cv2.resize(frame, (720, 720))\n",
    "        frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "    \n",
    "    frame_num += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "frames_array = np.array(frames)\n",
    "with open('data/frames.pkl', 'wb') as f:\n",
    "    pickle.dump(frames_array, f)\n",
    "\n",
    "print(f\"Done! Extracted {len(frames)} frames\")\n",
    "print(f\"Shape: {frames_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fcfc93-5bdc-46e9-9f8c-632bf6a6b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.12/site-packages (from omegaconf) (6.0.2)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d007ee-2739-4035-9ad7-c28378b6fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting trimesh\n",
      "  Downloading trimesh-4.11.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.12/site-packages (from trimesh) (1.26.4)\n",
      "Downloading trimesh-4.11.2-py3-none-any.whl (740 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m740.3/740.3 kB\u001b[0m \u001b[31m189.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: trimesh\n",
      "Successfully installed trimesh-4.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d13679-5048-4ef2-97bd-aa6244e9a777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.13.0\n",
      "Reading package lists... Done\n",
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n"
     ]
    }
   ],
   "source": [
    "# Install build dependencies\n",
    "!pip install ninja\n",
    "!apt-get update && apt-get install -y libsparsehash-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f791f5b4-cc34-4679-b8ab-2a3f631796b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (13: Permission denied)\n"
     ]
    }
   ],
   "source": [
    "!apt-get update && apt-get install -y libsparsehash-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef8b8f7-a8b5-464f-b278-92afe7b99f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapeR/dataset/point_cloud.py:efficient 3D sparse convolutions via torchsparse.\n",
      "ShapeR/dataset/point_cloud.py:import torchsparse\n",
      "ShapeR/dataset/point_cloud.py:from torchsparse.utils.collate import sparse_collate\n",
      "ShapeR/dataset/point_cloud.py:        sparse_tensor: torchsparse.SparseTensor.\n",
      "ShapeR/dataset/point_cloud.py:        # Convert to torchsparse.SparseTensor\n",
      "ShapeR/dataset/point_cloud.py:        pc_sparse_tensor = torchsparse.SparseTensor(\n",
      "ShapeR/dataset/shaper_dataset.py:import torchsparse\n",
      "ShapeR/dataset/shaper_dataset.py:            if isinstance(v, torchsparse.SparseTensor) or isinstance(v, torch.Tensor):\n",
      "ShapeR/infer_shape.py:# important! We are using an old version of torchsparse, please use the legacy version otherwise you will get errors,\\\n",
      "ShapeR/infer_shape.py:# since torchsparse changed their datastructures in newer versions\n",
      "ShapeR/model/flow_matching/shaper_denoiser.py:from torchsparse import SparseTensor\n",
      "ShapeR/model/pointcloud_encoder.py:import torchsparse\n",
      "ShapeR/model/pointcloud_encoder.py:import torchsparse.nn as spnn\n",
      "ShapeR/model/pointcloud_encoder.py:    \"\"\"Index into a batched torchsparse.SparseTensor.\n",
      "ShapeR/model/pointcloud_encoder.py:        sparse_tensor: a torchsparse.SparseTensor that is the output of\n",
      "ShapeR/model/pointcloud_encoder.py:            torchsparse.utils.collate.sparse_collate().\n",
      "ShapeR/model/pointcloud_encoder.py:        torchsparse.SparseTensor with no batch dimension.\n",
      "ShapeR/model/pointcloud_encoder.py:    return torchsparse.SparseTensor(\n",
      "ShapeR/model/pointcloud_encoder.py:    \"\"\"Un-Collate a batched torchsparse.SparseTensor.\n",
      "ShapeR/model/pointcloud_encoder.py:        sparse_tensor: a torchsparse.SparseTensor that is the output of\n"
     ]
    }
   ],
   "source": [
    "# See where torchsparse is used in the codebase\n",
    "!grep -r \"torchsparse\" ShapeR/ --include=\"*.py\" | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a31166a-bde1-4825-abb5-191f2f5ee51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-07 04:59:55--  https://github.com/sparsehash/sparsehash/archive/refs/tags/sparsehash-2.0.4.tar.gz\n",
      "140.82.114.4thub.com (github.com)... \n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/sparsehash/sparsehash/tar.gz/refs/tags/sparsehash-2.0.4 [following]\n",
      "--2026-02-07 04:59:56--  https://codeload.github.com/sparsehash/sparsehash/tar.gz/refs/tags/sparsehash-2.0.4\n",
      "140.82.112.10eload.github.com (codeload.github.com)... \n",
      "connected. to codeload.github.com (codeload.github.com)|140.82.112.10|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘sparsehash-2.0.4.tar.gz’\n",
      "\n",
      "sparsehash-2.0.4.ta     [ <=>                ] 315.58K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2026-02-07 04:59:56 (2.41 MB/s) - ‘sparsehash-2.0.4.tar.gz’ saved [323154]\n",
      "\n",
      "Collecting git+https://github.com/mit-han-lab/torchsparse.git\n",
      "  Cloning https://github.com/mit-han-lab/torchsparse.git to /tmp/pip-req-build-ducmirjw\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/mit-han-lab/torchsparse.git /tmp/pip-req-build-ducmirjw\n",
      "  Resolved https://github.com/mit-han-lab/torchsparse.git to commit 385f5ce8718fcae93540511b7f5832f4e71fd835\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (1.26.4)\n",
      "Collecting backports.cached_property (from torchsparse==2.1.0)\n",
      "  Downloading backports.cached_property-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (0.45.1)\n",
      "Collecting rootpath (from torchsparse==2.1.0)\n",
      "  Downloading rootpath-0.1.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (0.20.1+cu124)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (1.17.0)\n",
      "Collecting coloredlogs>=10.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (3.0.1)\n",
      "Collecting colour-runner>=0.0.5 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading colour_runner-0.1.1-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Collecting deepdiff>=3.3.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (2.19.1)\n",
      "Collecting tox>=3.0.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading tox-4.34.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting coverage>=4.5.2 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading coverage-7.13.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting codecov>=2.0.15 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading codecov-2.1.13-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch->torchsparse==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision->torchsparse==2.1.0) (11.1.0)\n",
      "Requirement already satisfied: requests>=2.7.9 in /opt/conda/lib/python3.12/site-packages (from codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2.32.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs>=10.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blessings (from colour-runner>=0.0.5->rootpath->torchsparse==2.1.0)\n",
      "  Downloading blessings-1.7-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting orderly-set<6,>=5.4.1 (from deepdiff>=3.3.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cachetools>=6.2.4 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading cachetools-7.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting chardet>=5.2 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /opt/conda/lib/python3.12/site-packages (from tox>=3.0.0->rootpath->torchsparse==2.1.0) (0.4.6)\n",
      "Collecting filelock (from torch->torchsparse==2.1.0)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting packaging>=25 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting platformdirs>=4.5.1 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pluggy>=1.6 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyproject-api>=1.10 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading pyproject_api-1.10.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting virtualenv>=20.35.4 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch->torchsparse==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2024.12.14)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.35.4->tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Downloading backports.cached_property-1.0.2-py3-none-any.whl (6.1 kB)\n",
      "Downloading rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Downloading coverage-7.13.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (254 kB)\n",
      "Downloading deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
      "Downloading tox-4.34.1-py3-none-any.whl (176 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading cachetools-7.0.0-py3-none-any.whl (13 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
      "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
      "Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading pyproject_api-1.10.0-py3-none-any.whl (13 kB)\n",
      "Downloading virtualenv-20.36.1-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Building wheels for collected packages: torchsparse\n",
      "  Building wheel for torchsparse (setup.py) ...error\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[169 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m torchsparse version: 2.1.0\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backends.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/operators.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/tensor.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/version.py -> build/lib.linux-x86_64-cpython-312/torchsparse\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/backbones\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backbones/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/backbones\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backbones/resnet.py -> build/lib.linux-x86_64-cpython-312/torchsparse/backbones\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backbones/unet.py -> build/lib.linux-x86_64-cpython-312/torchsparse/backbones\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/collate.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/quantize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/tensor_cache.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/to_dense.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/tune.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/utils/utils.py -> build/lib.linux-x86_64-cpython-312/torchsparse/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/backbones/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backbones/modules/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/backbones/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/backbones/modules/blocks.py -> build/lib.linux-x86_64-cpython-312/torchsparse/backbones/modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/activation.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/count.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/crop.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/devoxelize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/hash.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/pooling.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/query.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/voxelize.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/activation.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/bev.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/conv.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/crop.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/norm.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/modules/pooling.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/utils/apply.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/utils/kernel.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/conv.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/conv_config.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/conv_mode.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/func/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/func/fetch_on_demand.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/func/gather_scatter.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/func/implicit_gemm.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/func\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/hash\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/hash/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/hash\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/hash/hash.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/hash\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/hash/query.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/hash\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/build_kmap.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/downsample.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/upsample.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/utils/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/utils/collections.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/utils\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/utils/compat.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/func/__init__.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/func/hashmap.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap/func\n",
      "  \u001b[31m   \u001b[0m copying torchsparse/nn/functional/conv/kmap/func/hashmap_on_the_fly.py -> build/lib.linux-x86_64-cpython-312/torchsparse/nn/functional/conv/kmap/func\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torchsparse.backend' extension\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/convolution\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/devoxelize\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hash\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/others\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/voxelize\n",
      "  \u001b[31m   \u001b[0m Emitting ninja build file /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/build.ninja...\n",
      "  \u001b[31m   \u001b[0m Compiling objects...\n",
      "  \u001b[31m   \u001b[0m Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "  \u001b[31m   \u001b[0m [1/8] c++ -MMD -MF /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/devoxelize/devoxelize_cpu.o.d -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c -c /tmp/pip-req-build-ducmirjw/torchsparse/backend/devoxelize/devoxelize_cpu.cpp -o /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/devoxelize/devoxelize_cpu.o -g -O3 -fopenmp -lgomp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [2/8] c++ -MMD -MF /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/convolution/convolution_gather_scatter_cpu.o.d -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c -c /tmp/pip-req-build-ducmirjw/torchsparse/backend/convolution/convolution_gather_scatter_cpu.cpp -o /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/convolution/convolution_gather_scatter_cpu.o -g -O3 -fopenmp -lgomp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m [3/8] c++ -MMD -MF /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o.d -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c -c /tmp/pip-req-build-ducmirjw/torchsparse/backend/hashmap/hashmap_cpu.cpp -o /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o -g -O3 -fopenmp -lgomp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m \u001b[31mFAILED: [code=1] \u001b[0m/tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o\n",
      "  \u001b[31m   \u001b[0m c++ -MMD -MF /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o.d -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c -c /tmp/pip-req-build-ducmirjw/torchsparse/backend/hashmap/hashmap_cpu.cpp -o /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hashmap/hashmap_cpu.o -g -O3 -fopenmp -lgomp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m In file included from /home/jovyan/local/include/google/dense_hash_map:34,\n",
      "  \u001b[31m   \u001b[0m                  from /tmp/pip-req-build-ducmirjw/torchsparse/backend/hashmap/hashmap_cpu.hpp:7,\n",
      "  \u001b[31m   \u001b[0m                  from /tmp/pip-req-build-ducmirjw/torchsparse/backend/hashmap/hashmap_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m /home/jovyan/local/include/sparsehash/dense_hash_map:99:10: fatal error: sparsehash/internal/sparseconfig.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m    99 | #include <sparsehash/internal/sparseconfig.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m [4/8] c++ -MMD -MF /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hash/hash_cpu.o.d -pthread -B /opt/conda/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.12/site-packages/torch/include -I/opt/conda/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.12/site-packages/torch/include/TH -I/opt/conda/lib/python3.12/site-packages/torch/include/THC -I/opt/conda/include/python3.12 -c -c /tmp/pip-req-build-ducmirjw/torchsparse/backend/hash/hash_cpu.cpp -o /tmp/pip-req-build-ducmirjw/build/temp.linux-x86_64-cpython-312/torchsparse/backend/hash/hash_cpu.o -g -O3 -fopenmp -lgomp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=backend -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m ninja: build stopped: subcommand failed.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2104, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     subprocess.run(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/subprocess.py\", line 571, in run\n",
      "  \u001b[31m   \u001b[0m     raise CalledProcessError(retcode, process.args,\n",
      "  \u001b[31m   \u001b[0m subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-req-build-ducmirjw/setup.py\", line 42, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 186, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 202, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 983, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/dist.py\", line 999, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/command/bdist_wheel.py\", line 379, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 339, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/dist.py\", line 999, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/command/build.py\", line 136, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 339, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/dist.py\", line 999, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 1002, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 99, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 365, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 868, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     build_ext.build_extensions(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 481, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     self._build_extensions_serial()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 507, in _build_extensions_serial\n",
      "  \u001b[31m   \u001b[0m     self.build_extension(ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/command/build_ext.py\", line 264, in build_extension\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_extension(self, ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/Cython/Distutils/build_ext.py\", line 135, in build_extension\n",
      "  \u001b[31m   \u001b[0m     super(build_ext, self).build_extension(ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/setuptools/_distutils/command/build_ext.py\", line 562, in build_extension\n",
      "  \u001b[31m   \u001b[0m     objects = self.compiler.compile(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 681, in unix_wrap_ninja_compile\n",
      "  \u001b[31m   \u001b[0m     _write_ninja_file_and_compile_objects(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 1784, in _write_ninja_file_and_compile_objects\n",
      "  \u001b[31m   \u001b[0m     _run_ninja_build(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.12/site-packages/torch/utils/cpp_extension.py\", line 2120, in _run_ninja_build\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(message) from e\n",
      "  \u001b[31m   \u001b[0m RuntimeError: Error compiling objects for extension\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torchsparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torchsparse\n",
      "Failed to build torchsparse\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (torchsparse)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Create a local directory for sparsehash headers\n",
    "!mkdir -p ~/local/include\n",
    "\n",
    "# Download and extract sparsehash\n",
    "!wget https://github.com/sparsehash/sparsehash/archive/refs/tags/sparsehash-2.0.4.tar.gz\n",
    "!tar -xzf sparsehash-2.0.4.tar.gz\n",
    "!cp -r sparsehash-sparsehash-2.0.4/src/sparsehash ~/local/include/\n",
    "!cp -r sparsehash-sparsehash-2.0.4/src/google ~/local/include/\n",
    "\n",
    "# Set environment variables to help the compiler find the headers\n",
    "os.environ['CPLUS_INCLUDE_PATH'] = os.path.expanduser('~/local/include')\n",
    "os.environ['C_INCLUDE_PATH'] = os.path.expanduser('~/local/include')\n",
    "\n",
    "# Now try installing torchsparse\n",
    "!pip install git+https://github.com/mit-han-lab/torchsparse.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778eb618-75a0-4d97-a3aa-f34f80a84715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for a BSD-compatible install... /usr/bin/install -c\n",
      "yescking whether build environment is sane... \n",
      "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
      "checking for gawk... no\n",
      "checking for mawk... mawk\n",
      "checking whether make sets $(MAKE)... yes\n",
      "checking for g++... g++\n",
      "checking whether the C++ compiler works... yes\n",
      "checking for C++ compiler default output file name... a.out\n",
      "checking for suffix of executables... \n",
      "noecking whether we are cross compiling... \n",
      "ohecking for suffix of object files... \n",
      "checking whether we are using the GNU C++ compiler... yes\n",
      "yescking whether g++ accepts -g... \n",
      "checking for style of include used by make... GNU\n",
      "gcc3king dependency style of g++... \n",
      "checking for gcc... gcc\n",
      "yescking whether we are using the GNU C compiler... \n",
      "yescking whether gcc accepts -g... \n",
      "none neededr gcc option to accept ISO C89... \n",
      "gcc3king dependency style of gcc... \n",
      "gcc -Eng how to run the C preprocessor... \n",
      "checking for grep that handles long lines and -e... /usr/bin/grep\n",
      "checking for egrep... /usr/bin/grep -E\n",
      "yescking for ANSI C header files... \n",
      "yescking for memcpy... \n",
      "yescking for memmove... \n",
      "yescking for sys/types.h... \n",
      "yescking for sys/stat.h... \n",
      "checking for stdlib.h... yes\n",
      "checking for string.h... yes\n",
      "yescking for memory.h... \n",
      "yescking for strings.h... \n",
      "yescking for inttypes.h... \n",
      "yescking for stdint.h... \n",
      "yescking for unistd.h... \n",
      "yescking for uint16_t... \n",
      "yescking for u_int16_t... \n",
      "noecking for __uint16... \n",
      "yescking for long long... \n",
      "yescking sys/resource.h usability... \n",
      "yescking sys/resource.h presence... \n",
      "checking for sys/resource.h... yes\n",
      "checking for unistd.h... (cached) yes\n",
      "yescking sys/time.h usability... \n",
      "checking sys/time.h presence... yes\n",
      "checking for sys/time.h... yes\n",
      "yescking sys/utsname.h usability... \n",
      "yescking sys/utsname.h presence... \n",
      "checking for sys/utsname.h... yes\n",
      "checking how to run the C++ preprocessor... g++ -E\n",
      "checking google/malloc_extension.h usability... no\n",
      "noecking google/malloc_extension.h presence... \n",
      "checking for google/malloc_extension.h... no\n",
      "checking whether the compiler implements namespaces... yes\n",
      "<unordered_map>cation of hash_map... \n",
      "<functional> to include hash_fun directly... \n",
      "configure: creating ./config.status\n",
      "config.status: creating Makefile\n",
      "config.status: creating src/config.h\n",
      "config.status: src/config.h is unchanged\n",
      "config.status: executing depfiles commands\n",
      "make  install-am\n",
      "make[1]: Entering directory '/home/jovyan/sparsehash-sparsehash-2.0.4'\n",
      "echo 'prefix=/home/jovyan/local' > \"libsparsehash.pc\".tmp\n",
      "echo 'exec_prefix='`echo '/home/jovyan/local' | sed 's@^/home/jovyan/local@${prefix}@'` >> \"libsparsehash.pc\".tmp\n",
      "echo 'libdir='`echo '/home/jovyan/local/lib' | sed 's@^/home/jovyan/local@${exec_prefix}@'` >> \"libsparsehash.pc\".tmp\n",
      "echo 'includedir='`echo '/home/jovyan/local/include' | sed 's@^/home/jovyan/local@${prefix}@'` >> \"libsparsehash.pc\".tmp\n",
      "echo '' >> \"libsparsehash.pc\".tmp\n",
      "echo 'Name: sparsehash' >> \"libsparsehash.pc\".tmp\n",
      "echo 'Version: 2.0.2' >> \"libsparsehash.pc\".tmp\n",
      "grep '^Summary:' ./packages/rpm/rpm.spec | sed s/^Summary:/Description:/ | head -n1 >> \"libsparsehash.pc\".tmp\n",
      "grep '^URL: ' ./packages/rpm/rpm.spec >> \"libsparsehash.pc\".tmp\n",
      "echo 'Requires:' >> \"libsparsehash.pc\".tmp\n",
      "echo 'Libs:' >> \"libsparsehash.pc\".tmp\n",
      "echo 'Cflags: -I${includedir}' >> \"libsparsehash.pc\".tmp\n",
      "mv -f \"libsparsehash.pc\".tmp \"libsparsehash.pc\"\n",
      "make[2]: Entering directory '/home/jovyan/sparsehash-sparsehash-2.0.4'\n",
      "test -z \"/home/jovyan/local/lib\" || /usr/bin/mkdir -p \"/home/jovyan/local/lib\"\n",
      "test -z \"/home/jovyan/local/share/doc/sparsehash-2.0.2\" || /usr/bin/mkdir -p \"/home/jovyan/local/share/doc/sparsehash-2.0.2\"\n",
      " /usr/bin/install -c -m 644 AUTHORS COPYING ChangeLog INSTALL NEWS README README_windows.txt TODO doc/dense_hash_map.html doc/dense_hash_set.html doc/sparse_hash_map.html doc/sparse_hash_set.html doc/sparsetable.html doc/implementation.html doc/performance.html doc/index.html doc/designstyle.css '/home/jovyan/local/share/doc/sparsehash-2.0.2'\n",
      "test -z \"/home/jovyan/local/include/google\" || /usr/bin/mkdir -p \"/home/jovyan/local/include/google\"\n",
      " /usr/bin/install -c -m 644 src/google/dense_hash_map src/google/dense_hash_set src/google/sparse_hash_map src/google/sparse_hash_set src/google/sparsetable src/google/template_util.h src/google/type_traits.h '/home/jovyan/local/include/google'\n",
      "test -z \"/home/jovyan/local/include/google/sparsehash\" || /usr/bin/mkdir -p \"/home/jovyan/local/include/google/sparsehash\"\n",
      " /usr/bin/install -c -m 644 src/google/sparsehash/densehashtable.h src/google/sparsehash/sparsehashtable.h src/google/sparsehash/hashtable-common.h src/google/sparsehash/libc_allocator_with_realloc.h '/home/jovyan/local/include/google/sparsehash'\n",
      "test -z \"/home/jovyan/local/include/sparsehash/internal\" || /usr/bin/mkdir -p \"/home/jovyan/local/include/sparsehash/internal\"\n",
      " /usr/bin/install -c -m 644 src/sparsehash/internal/densehashtable.h src/sparsehash/internal/sparsehashtable.h src/sparsehash/internal/hashtable-common.h src/sparsehash/internal/libc_allocator_with_realloc.h '/home/jovyan/local/include/sparsehash/internal'\n",
      "test -z \"/home/jovyan/local/include/sparsehash/internal\" || /usr/bin/mkdir -p \"/home/jovyan/local/include/sparsehash/internal\"\n",
      " /usr/bin/install -c -m 644 src/sparsehash/internal/sparseconfig.h '/home/jovyan/local/include/sparsehash/internal'\n",
      "test -z \"/home/jovyan/local/lib/pkgconfig\" || /usr/bin/mkdir -p \"/home/jovyan/local/lib/pkgconfig\"\n",
      " /usr/bin/install -c -m 644 libsparsehash.pc '/home/jovyan/local/lib/pkgconfig'\n",
      "test -z \"/home/jovyan/local/include/sparsehash\" || /usr/bin/mkdir -p \"/home/jovyan/local/include/sparsehash\"\n",
      " /usr/bin/install -c -m 644 src/sparsehash/dense_hash_map src/sparsehash/dense_hash_set src/sparsehash/sparse_hash_map src/sparsehash/sparse_hash_set src/sparsehash/sparsetable src/sparsehash/template_util.h src/sparsehash/type_traits.h '/home/jovyan/local/include/sparsehash'\n",
      "make[2]: Leaving directory '/home/jovyan/sparsehash-sparsehash-2.0.4'\n",
      "make[1]: Leaving directory '/home/jovyan/sparsehash-sparsehash-2.0.4'\n",
      "Collecting git+https://github.com/mit-han-lab/torchsparse.git\n",
      "  Cloning https://github.com/mit-han-lab/torchsparse.git to /tmp/pip-req-build-x8sb0vwu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/mit-han-lab/torchsparse.git /tmp/pip-req-build-x8sb0vwu\n",
      "  Resolved https://github.com/mit-han-lab/torchsparse.git to commit 385f5ce8718fcae93540511b7f5832f4e71fd835\n",
      "  Preparing metadata (setup.py) ... \u001b[?25done\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (1.26.4)\n",
      "Collecting backports.cached_property (from torchsparse==2.1.0)\n",
      "  Using cached backports.cached_property-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (4.12.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (0.45.1)\n",
      "Collecting rootpath (from torchsparse==2.1.0)\n",
      "  Using cached rootpath-0.1.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.12/site-packages (from torchsparse==2.1.0) (0.20.1+cu124)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (1.17.0)\n",
      "Collecting coloredlogs>=10.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (3.0.1)\n",
      "Collecting colour-runner>=0.0.5 (from rootpath->torchsparse==2.1.0)\n",
      "  Using cached colour_runner-0.1.1-py2.py3-none-any.whl.metadata (828 bytes)\n",
      "Collecting deepdiff>=3.3.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Using cached deepdiff-8.6.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rootpath->torchsparse==2.1.0) (2.19.1)\n",
      "Collecting tox>=3.0.0 (from rootpath->torchsparse==2.1.0)\n",
      "  Using cached tox-4.34.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting coverage>=4.5.2 (from rootpath->torchsparse==2.1.0)\n",
      "  Downloading coverage-7.13.4-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting codecov>=2.0.15 (from rootpath->torchsparse==2.1.0)\n",
      "  Using cached codecov-2.1.13-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch->torchsparse==2.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch->torchsparse==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision->torchsparse==2.1.0) (11.1.0)\n",
      "Requirement already satisfied: requests>=2.7.9 in /opt/conda/lib/python3.12/site-packages (from codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2.32.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs>=10.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting blessings (from colour-runner>=0.0.5->rootpath->torchsparse==2.1.0)\n",
      "  Using cached blessings-1.7-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting orderly-set<6,>=5.4.1 (from deepdiff>=3.3.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached orderly_set-5.5.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cachetools>=6.2.4 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached cachetools-7.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting chardet>=5.2 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /opt/conda/lib/python3.12/site-packages (from tox>=3.0.0->rootpath->torchsparse==2.1.0) (0.4.6)\n",
      "Collecting filelock (from torch->torchsparse==2.1.0)\n",
      "  Using cached filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting packaging>=25 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting platformdirs>=4.5.1 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pluggy>=1.6 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyproject-api>=1.10 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached pyproject_api-1.10.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting virtualenv>=20.35.4 (from tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached virtualenv-20.36.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch->torchsparse==2.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.7.9->codecov>=2.0.15->rootpath->torchsparse==2.1.0) (2024.12.14)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.35.4->tox>=3.0.0->rootpath->torchsparse==2.1.0)\n",
      "  Using cached distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Using cached backports.cached_property-1.0.2-py3-none-any.whl (6.1 kB)\n",
      "Using cached rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
      "Using cached codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Downloading coverage-7.13.4-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (254 kB)\n",
      "Using cached deepdiff-8.6.1-py3-none-any.whl (91 kB)\n",
      "Using cached tox-4.34.1-py3-none-any.whl (176 kB)\n",
      "Using cached filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached cachetools-7.0.0-py3-none-any.whl (13 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached orderly_set-5.5.0-py3-none-any.whl (13 kB)\n",
      "Using cached packaging-26.0-py3-none-any.whl (74 kB)\n",
      "Using cached platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
      "Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Using cached pyproject_api-1.10.0-py3-none-any.whl (13 kB)\n",
      "Using cached virtualenv-20.36.1-py3-none-any.whl (6.0 MB)\n",
      "Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Using cached distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Building wheels for collected packages: torchsparse\n",
      "  Building wheel for torchsparse (setupdone\n",
      "\u001b[?25h  Created wheel for torchsparse: filename=torchsparse-2.1.0-cp312-cp312-linux_x86_64.whl size=11932588 sha256=31cf1e67e32ae4847cf2f5893572a28e55a3595a5ba41166c656d1c1dbedc6ef\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9u6i83dl/wheels/8e/31/20/f32e121a614d316912debca2d61f65dfc928d56a762775db51\n",
      "Successfully built torchsparse\n",
      "Installing collected packages: distlib, pluggy, platformdirs, packaging, orderly-set, humanfriendly, filelock, coverage, chardet, cachetools, blessings, backports.cached_property, virtualenv, pyproject-api, deepdiff, colour-runner, coloredlogs, codecov, tox, rootpath, torchsparse\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.5.0\n",
      "    Uninstalling pluggy-1.5.0:\n",
      "      Successfully uninstalled pluggy-1.5.0\n",
      "  Attempting uninstall: platformdirs\n",
      "    Found existing installation: platformdirs 4.3.6\n",
      "    Uninstalling platformdirs-4.3.6:\n",
      "      Successfully uninstalled platformdirs-4.3.6\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.13.1\n",
      "    Uninstalling filelock-3.13.1:\n",
      "      Successfully uninstalled filelock-3.13.1\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.5.2\n",
      "    Uninstalling cachetools-5.5.2:\n",
      "      Successfully uninstalled cachetools-5.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.38.0 requires cachetools<6.0,>=2.0.0, but you have cachetools 7.0.0 which is incompatible.\n",
      "langchain-core 0.3.51 requires packaging<25,>=23.2, but you have packaging 26.0 which is incompatible.\n",
      "lightning 2.5.1 requires packaging<25.0,>=20.0, but you have packaging 26.0 which is incompatible.\n",
      "mlflow-skinny 2.21.3 requires cachetools<6,>=5.0.0, but you have cachetools 7.0.0 which is incompatible.\n",
      "mlflow-skinny 2.21.3 requires packaging<25, but you have packaging 26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed backports.cached_property-1.0.2 blessings-1.7 cachetools-7.0.0 chardet-5.2.0 codecov-2.1.13 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.13.4 deepdiff-8.6.1 distlib-0.4.0 filelock-3.20.3 humanfriendly-10.0 orderly-set-5.5.0 packaging-26.0 platformdirs-4.5.1 pluggy-1.6.0 pyproject-api-1.10.0 rootpath-0.1.1 torchsparse-2.1.0 tox-4.34.1 virtualenv-20.36.1\n"
     ]
    }
   ],
   "source": [
    "# We need to generate the sparseconfig.h file\n",
    "!cd sparsehash-sparsehash-2.0.4 && ./configure --prefix=$HOME/local\n",
    "!cd sparsehash-sparsehash-2.0.4 && make install\n",
    "\n",
    "# Now try installing torchsparse again\n",
    "import os\n",
    "os.environ['CPLUS_INCLUDE_PATH'] = os.path.expanduser('~/local/include')\n",
    "os.environ['C_INCLUDE_PATH'] = os.path.expanduser('~/local/include')\n",
    "\n",
    "!pip install git+https://github.com/mit-han-lab/torchsparse.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d624ffa6-abd7-4e6e-824b-f20b9369aea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 40, in <module>\n",
      "KeyError: 'torch25'\n"
     ]
    }
   ],
   "source": [
    "!python -c \"$(curl -fsSL https://raw.githubusercontent.com/mit-han-lab/torchsparse/master/install.py)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2bfb45-004c-4806-9570-5f7834f3b3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Using cached einops-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached einops-0.8.2-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348a8f74-ea61-4c61-9c3f-8cdc008d34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sophuspy\n",
      "  Using cached sophuspy-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from sophuspy) (1.26.4)\n",
      "Using cached sophuspy-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (238 kB)\n",
      "Installing collected packages: sophuspy\n",
      "Successfully installed sophuspy-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sophuspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09a0658-558e-4b1f-9d41-83902529a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchdiffeq\n",
      "  Using cached torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
      "Requirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.12/site-packages (from torchdiffeq) (2.5.1+cu124)\n",
      "Requirement already satisfied: scipy>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from torchdiffeq) (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.12/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n",
      "Using cached torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: torchdiffeq\n",
      "Successfully installed torchdiffeq-0.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57254e8-5959-4287-bac5-1b674b6f9952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch_cluster\n",
      "  Using cached torch_cluster-1.6.3-cp312-cp312-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from torch_cluster) (1.15.1)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /opt/conda/lib/python3.12/site-packages (from scipy->torch_cluster) (1.26.4)\n",
      "Installing collected packages: torch_cluster\n",
      "Successfully installed torch_cluster-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "722d8890-1411-405b-9fa8-643d81304940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50:     def __getitem__(self, idx):\n",
      "51:         sample_path = self.paths[idx]\n",
      "52:         pkl_sample = pickle.load(open(sample_path, \"rb\"))\n",
      "53: \n",
      "54:         semi_dense_points = pkl_sample[\"points_model\"].numpy()\n",
      "55:         bounds = pkl_sample[\"bounds\"].numpy()\n",
      "56:         semi_dense_theta = pkl_sample[\"inv_dist_std\"].numpy()[:]\n",
      "57:         semi_dense_phi = pkl_sample[\"dist_std\"].numpy()[:]\n",
      "58:         scale = 0.9 / np.max(bounds)\n",
      "59:         semi_dense_points[:, :3] *= scale\n",
      "60: \n",
      "61:         valid = np.all(np.abs(semi_dense_points) <= 1.0, axis=-1)\n",
      "62:         semi_dense_points = semi_dense_points[valid, :]\n",
      "63:         semi_dense_theta = semi_dense_theta[valid]\n",
      "64:         semi_dense_phi = semi_dense_phi[valid]\n",
      "65: \n",
      "66:         # threshold the semi-dense points\n",
      "67:         selected_semi_dense_points = semi_dense_points\n",
      "68: \n",
      "69:         thres_theta = self.config.dataset.semi_dense_threshold_theta\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import pickle; f = open('ShapeR/dataset/shaper_dataset.py', 'r'); [print(f'{i}: {line}', end='') for i, line in enumerate(f.readlines()[50:70], 50)]; f.close()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5f05c33-ead0-4b04-b1d9-8ebb04600611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected pickle keys: ['points_model', 'bounds', 'inv_dist_std', 'dist_std', 'images', 'masks', 'poses']\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import pickle; sample_keys = ['points_model', 'bounds', 'inv_dist_std', 'dist_std', 'images', 'masks', 'poses']; print('Expected pickle keys:', sample_keys)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc3e768c-c5db-42f8-b281-7fd08632271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  helper.py\t     projection_utils.py  view_selection_heuristic.py\n",
      "__pycache__  point_cloud.py  ray_utils.py\n",
      "camera.py    pose.py\t     tensor_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "!ls ShapeR/preprocessing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a326405d-4511-4417-94b4-1746430dac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ShapeR: Robust Conditional 3D Shape Generation from Casual Captures\n",
      "\n",
      "![teaser](resources/Teaser.jpg)\n",
      "\n",
      "ShapeR introduces a novel approach to metric shape generation. Given an input image sequence, preprocessing extracts per-object metric sparse SLAM points, images, poses, and captions using off-the-shelf methods. A rectified flow transformer operating on VecSet latents conditions on these multimodal inputs to generate a shape code, which is decoded into the object’s mesh. By applying the model object-centrically to each detected object, we obtain a metric reconstruction of the entire scene.\n",
      "\n",
      "[Project Page](http://facebookresearch.github.io/ShapeR)  |  [Paper](https://cdn.jsdelivr.net/gh/facebookresearch/ShapeR@main/resources/ShapeR.pdf) | [Arxiv](https://arxiv.org/abs/2601.11514)  |  [Video](https://www.youtube.com/watch?v=EbY30KAA55I)  |  [HF-Model](https://huggingface.co/facebook/ShapeR/)  |  [HF Evaluation Dataset](https://huggingface.co/datasets/facebook/ShapeR-Evaluation)\n",
      "\n",
      "## Installation\n",
      "\n",
      "Refer to [INSTALL.md](INSTALL.md) for detailed instructions on setting up the environment.\n",
      "\n",
      "## Usage\n",
      "\n",
      "### Inference\n",
      "\n",
      "```bash\n",
      "python infer_shape.py --input_pkl <sample.pkl> --config balance --output_dir output\n",
      "```\n",
      "\n",
      "**Arguments:**\n",
      "- `--input_pkl`: Path to preprocessed pickle file (relative to `data/`)\n",
      "- `--config`: Preset configuration\n",
      "  - `quality`: 16 views, 50 steps (best quality, slowest)\n",
      "  - `balance`: 16 views, 25 steps (recommended)\n",
      "  - `speed`: 4 views, 10 steps (fastest)\n",
      "- `--output_dir`: Output directory for meshes and visualizations\n",
      "- `--do_transform_to_world`: Transform output mesh to world coordinates\n",
      "- `--remove_floating_geometry`: Remove disconnected mesh components (default: on)\n",
      "- `--simplify_mesh`: Reduce mesh complexity (default: on)\n",
      "- `--save_visualization`: Save comparison visualization (default: off)\n",
      "\n",
      "### Example\n",
      "\n",
      "```bash\n",
      "python infer_shape.py --input_pkl ADT1292__stool.pkl --config balance\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "- `<name>.glb`: Reconstructed 3D mesh\n",
      "- `VIS__<name>.jpg`: Visualization comparing input, prediction, and ground truth (--save_visualization is passed)\n",
      "\n",
      "![Example visualization](resources/output_vis_example.jpg)\n",
      "\n",
      "## Data Format\n",
      "\n",
      "This codebase assumes that a sequence has already been processed using the Aria MPS pipeline, along with an 3D object instance detector, resulting in the pickle files with the preprocessed data required for ShapeR ingestion.\n",
      "\n",
      "We release the **ShapeR Evaluation Dataset** containing preprocessed samples from Aria glasses captures. Each sample is a pickle file with point clouds, multi-view images, camera parameters, text captions, and ground truth meshes.\n",
      "\n",
      "For a detailed walkthrough of the data format, see the **[`explore_data.ipynb`](explore_data.ipynb)** notebook which includes:\n",
      "- Complete pickle file structure with all keys and their dimensions\n",
      "- Interactive 3D visualization of point clouds and meshes\n",
      "- Camera position visualization\n",
      "- Image and mask grid displays\n",
      "- DataLoader usage examples for both SLAM and RGB variants\n",
      "- Explanation of view selection strategies\n",
      "\n",
      "## Project Structure\n",
      "\n",
      "```\n",
      "ShapeR/\n",
      "├── infer_shape.py          # Main inference script\n",
      "├── explore_data.ipynb      # Data exploration notebook\n",
      "├── dataset/\n",
      "│   ├── shaper_dataset.py   # Dataset and dataloader\n",
      "│   ├── image_processor.py  # View selection and image preprocessing\n",
      "│   └── point_cloud.py      # Point cloud to SparseTensor\n",
      "├── model/\n",
      "│   ├── flow_matching/\n",
      "│   │   └── shaper_denoiser.py  # Flow matching denoiser\n",
      "│   ├── vae3d/\n",
      "│   │   └── autoencoder.py      # 3D VAE for mesh generation\n",
      "│   ├── pointcloud_encoder.py   # Sparse 3D convolution encoder\n",
      "│   └── dino_and_ray_feature_extractor.py  # Image feature extraction\n",
      "├── preprocessing/\n",
      "│   └── helper.py           # Fisheye rectification, camera utils\n",
      "├── postprocessing/\n",
      "│   └── helper.py           # Mesh cleanup, visualization\n",
      "├── checkpoints/            # Model weights (downloaded automatically)\n",
      "└── data/                   # Input pickle files\n",
      "```\n",
      "\n",
      "## License\n",
      "\n",
      "The majority of ShapeR is licensed under CC-BY-NC. See the [LICENSE](LICENSE) file for details. However portions of the project are available under separate license terms: see [NOTICE](NOTICE).\n",
      "\n",
      "## Citation\n",
      "\n",
      "If you find ShapeR useful for your research, please cite our paper:\n",
      "\n",
      "```bibtex\n",
      "@misc{siddiqui2026shaperrobustconditional3d,\n",
      "      title={ShapeR: Robust Conditional 3D Shape Generation from Casual Captures}, \n",
      "      author={Yawar Siddiqui and Duncan Frost and Samir Aroudj and Armen Avetisyan and Henry Howard-Jenkins and Daniel DeTone and Pierre Moulon and Qirui Wu and Zhengqin Li and Julian Straub and Richard Newcombe and Jakob Engel},\n",
      "      year={2026},\n",
      "      eprint={2601.11514},\n",
      "      archivePrefix={arXiv},\n",
      "      primaryClass={cs.CV},\n",
      "      url={https://arxiv.org/abs/2601.11514}, \n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "!cat ShapeR/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f4300b0-5a84-438d-b851-8af954fcb73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|████████████████████████| 5/5 [00:00<00:00, 99864.38it/s]\n",
      "Loading model...\n",
      "/home/jovyan/ShapeR/model/dinov2/layers/attention.py:34: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/jovyan/ShapeR/model/dinov2/layers/block.py:42: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "/home/jovyan/ShapeR/model/dinov2/layers/swiglu_ffn.py:55: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/jovyan/ShapeR/model/dinov2/hub/backbones.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(url, map_location=\"cpu\")\n",
      "tokenizer_config.json: 1.86kB [00:00, 9.17MB/s]\n",
      "spiece.model: 100%|██████████████████████████| 792k/792k [00:00<00:00, 4.71MB/s]\n",
      "special_tokens_map.json: 1.79kB [00:00, 16.0MB/s]\n",
      "config.json: 100%|█████████████████████████████| 591/591 [00:00<00:00, 9.68MB/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "pytorch_model.bin: 100%|███████████████████| 11.4G/11.4G [02:09<00:00, 88.3MB/s]\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "model.safetensors: 100%|███████████████████| 11.4G/11.4G [06:05<00:00, 31.2MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████| 905/905 [00:00<00:00, 10.1MB/s]\n",
      "vocab.json: 961kB [00:00, 4.36MB/s]\n",
      "merges.txt: 525kB [00:00, 9.08MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 389/389 [00:00<00:00, 5.72MB/s]\n",
      "tokenizer.json: 2.22MB [00:00, 18.1MB/s]\n",
      "config.json: 4.52kB [00:00, 5.40MB/s]\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "model.safetensors: 100%|████████████████████| 1.71G/1.71G [00:11<00:00, 147MB/s]\n",
      "Loading input pkl from data/frames.pkl\n",
      "  0%|                                                     | 0/1 [00:11<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/ShapeR/infer_shape.py\", line 220, in <module>\n",
      "    main()\n",
      "  File \"/home/jovyan/ShapeR/infer_shape.py\", line 167, in main\n",
      "    for batch in tqdm(inference_loader):\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "               ^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 701, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 757, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/home/jovyan/ShapeR/dataset/shaper_dataset.py\", line 55, in __getitem__\n",
      "    semi_dense_points = pkl_sample[\"points_model\"].numpy()\n",
      "                        ~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n"
     ]
    }
   ],
   "source": [
    "!python ShapeR/infer_shape.py --input_pkl data/frames.pkl --config balance --output_dir output --is_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e01bd3-31cd-4aa0-ade3-e88464dbc0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
